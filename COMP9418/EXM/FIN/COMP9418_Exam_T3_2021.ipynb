{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T3-2021 Exam\n",
    "\n",
    "**COMP9418 - Advanced Topics in Statistical Machine Learning**\n",
    "\n",
    "**University of New South Wales**\n",
    "\n",
    "**7th December, 2021**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding, please read and acknowledge the following (double-click on this cell and put an `X` between the brackets `[X]`):\n",
    "    \n",
    "- [X] I acknowledge that I will complete all of the work I submit for this exam without assistance from anyone else."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Instructions\n",
    "\n",
    "1. This exam will last for 12 hours, starting 7/12/2021 at 09:00:00 AEST and ending 7/12/2021 at 21:00:00 AEST.\n",
    "2. Questions will be answered from 9 am to 9 pm AEST. Questions should be posted in the [WebCMS forum](https://webcms3.cse.unsw.edu.au/COMP9418/21T3/forums/) (general questions) or sent by email to cs9418@cse.unsw.edu.au (sensitive questions).\n",
    "3. You must provide all answers in this Jupyter notebook. \n",
    "4. You must use the cells provided to answer the questions. Use markdown cells for textual answers and code cells for programming answers.\n",
    "5. Submit this exam by give (command line or WebCMS) before the deadline. If WebCMS submission is slow, or if you are submitting in the last hour, please submit using the give command on the CSE servers (via VLAB or ssh).\n",
    "The appropriate command is ```give cs9418 exam *.ipynb *.py```. We will not accept late submissions.\n",
    "6. The exam has three parts: Multiple choice questions (20%); Questions that require a textual answer (50%); and, programming questions in Python (30%).\n",
    "7. This exam is an open book exam. You are permitted to access papers and books as well as the course materials, including slides and solved tutorials. Please, in case of doubt, read the [UNSW guidance on open book exams](https://student.unsw.edu.au/open-book-and-take-home-exams).\n",
    "8. You are not permitted to communicate (email, phone, message, talk, etc.) with anyone during the exam, except COMP9418 staff via email or forum.\n",
    "9. Do not communicate your exam answers after you finish your exam. Some students may have extended time to complete the exam.\n",
    "10. Do not place your exam work in any location accessible to any other person, such as  Dropbox and Github.\n",
    "11. Ensure that no other person in your household can access your work.\n",
    "12. Do not disclose your zpass to any other person. If you have revealed your zpass, you should change it immediately.\n",
    "13. We will refer deliberate violations of exam conditions to Student Integrity as serious misconduct. \n",
    "14. This exam has nine questions. The total number of marks is 100.\n",
    "15. **Type your student number and name on the next cell.**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student identification\n",
    "\n",
    "**Name: Yiyan Yang**\n",
    "\n",
    "**Student ID: z5183946**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from DiscreteFactors import Factor\n",
    "from Graph import Graph\n",
    "from BayesNet import BayesNet\n",
    "from GaussianFactor import GaussianFactor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 [20 marks]\n",
    "\n",
    "Part 1 is composed of four multiple-choice questions of five marks each. To answer each question, double-click the cell with the alternatives and write an `X` between the `[ ]` of the chosen option.\n",
    "\n",
    "This is an example before inserting `X`\n",
    "\n",
    "1. [ ] Alternative one\n",
    "2. [ ] Alternative two\n",
    "\n",
    "This is an example after inserting `X`\n",
    "\n",
    "1. [X] Alternative one\n",
    "2. [ ] Alternative two\n",
    "\n",
    "For all four questions, choose only one among the alternatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Question 1 [5 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the directed Graph $G_D$ (left) and the undirected graph $G_U$ (right). Also, consider the probabilities distributions $P_D$ and $P_U$ that factorise according to $G_D$ and $G_U$, respectively. Select the **correct** alternative regarding graph separation and probability independence.\n",
    "\n",
    "![Graphs GD and GU](images/Question_separation.png \"Graph GD and GU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [ ] $dsep_{G_D}(B,F,D)$ and $sep_{G_U}(B,F,D)$. Therefore, $B \\perp D | F$ in both $P_D$ and $P_U$.\n",
    "2. [ ] $dsep_{G_D}(C,\\emptyset,D)$ and $sep_{G_U}(C,\\emptyset,D)$. Therefore, $C \\perp D$ in both $P_D$ and $P_U$.\n",
    "3. [ ] $\\neg dsep_{G_D}(B,F,D)$ and $\\neg sep_{G_U}(B,F,D)$. Therefore, $B \\not\\perp D | F$ in $P_D$ and $B \\not\\perp D | F$ in $P_U$.\n",
    "4. [X] $\\neg dsep_{G_D}(B,F,D)$ and $\\neg sep_{G_U}(C,\\emptyset,D)$. Therefore, $B \\not\\perp D | F$ in $P_D$ and $C \\not\\perp D$ in $P_U$.\n",
    "5. [ ] None of the above alternatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Question 2 [5 marks]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's suppose we apply the Expectation-Maximization (EM) approach to learning parameters from a complete (with no missing values) dataset. Choose the correct alternative:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [ ] EM will converge in a single iteration, and it will return the maximum-likelihood estimates independent of the initial parameter values.\n",
    "2. [ ] EM will converge in one or more iterations, and it will return the maximum-likelihood estimates independent of the initial parameter values.\n",
    "3. [X] EM will often converge to the maximum-likelihood estimates, but it will depend on the quality of the initial parameter values.\n",
    "4. [ ] EM will not converge to the maximum-likelihood estimates.\n",
    "5. [ ] EM is not applicable to complete data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Question 3 [5 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we used the Variable Elimination algorithm on a Gaussian Bayesian Network with elimination order $o$. The network has $N$ variables and the width of the network with elimination order $o$ is $w$. \n",
    "What is the time complexity of this algorithm? Choose the option with the tightest upper bound.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [X] $O(N e^w)$\n",
    "2. [ ] $O(N w^3)$\n",
    "3. [ ] $O(N w^2)$\n",
    "4. [ ] $O(N w)$\n",
    "5. [ ] $O(N \\log w)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Question 4 [5 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following three directed graphs, $G_1$, $G_2$ and $G_3$. \n",
    "\n",
    "![Graphs G1 G2 and G3](images/Question_MDL.png \"Graphs G_1, G_2 and G_3\")\n",
    "\n",
    "On a dataset $D$, $G_1$ has a log-likelihood of -32.4, $G_2$ has log-likelihood  of -28.3, and $G_3$ has log-likelihood of -15.2. $D$ contains 64 data points and six binary variables. Rank the three graphs using the Minimum Description Length (MDL) score, from best to worst on the dataset $D$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [ ] $G_1, G_2, G_3$\n",
    "2. [X] $G_1, G_3, G_2$\n",
    "3. [ ] $G_2, G_3, G_1$\n",
    "4. [ ] $G_3, G_2, G_1$\n",
    "5. [ ] $G_3, G_1, G_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# Part 2 [50 marks]\n",
    "\n",
    "Part 2 is composed of three open questions. To answer each question, edit the markdown cell after the question statement and insert your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Question 5 [20 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Andy and Lance are two metal detectorists that like to work together. Their hobby consists of using metal detectors to find buried metallic objects (targets). Andy uses an XP metal detector, while Lance operates a Minelab. When searching for a buried target, they both measure their machines' response before excavating the target. A target can be trash (bottle caps, cans, nails, etc.) or treasure (coins, rings, historical artefacts, etc.). \n",
    "\n",
    "The XP correctly recognises trash with 90% accuracy but has a lower accuracy in identifying treasure correctly, 70%. The Minelab machine identifies trash and treasure correctly with 80% and 70% accuracy, respectively. \n",
    "\n",
    "Both detectors are sensitive machines that may require calibration from time to time. The XP is a more robust machine, and the probability of being uncalibrated is only 1%. The Minelab has a higher chance of being uncalibrated, 5%. An uncalibrated device has its accuracy for detecting treasure reduced by 10% while leaving the trash accuracy unmodified. \n",
    "\n",
    "Given that 99% of the detected objects are trash, what is the probability of a target being a treasure given that both machines read treasure?\n",
    "\n",
    "1. [**5 Marks**] Show a Bayesian network structure (graph) for this problem. \n",
    "2. [**5 Marks**] **Briefly** explain your network.\n",
    "3. [**5 Marks**] Show the outcome space and network conditional probability tables (CPTs) for all variables. If any information is missing, assume a uniform distribution.\n",
    "4. [**5 Marks**] What is the answer to this question? Solve it as a programming exercise, i.e., provide a program that computes the solution. Is the numerical solution what you expect? **Briefly** comment on the resulting probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n -->\r\n<!-- Title: %3 Pages: 1 -->\r\n<svg width=\"248pt\" height=\"125pt\"\r\n viewBox=\"0.00 0.00 247.88 125.06\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(111.249 75.0023)\">\r\n<title>%3</title>\r\n<polygon fill=\"white\" stroke=\"none\" points=\"-111.249,50.0594 -111.249,-75.0023 136.629,-75.0023 136.629,50.0594 -111.249,50.0594\"/>\r\n<!-- Detector -->\r\n<g id=\"node1\" class=\"node\"><title>Detector</title>\r\n<ellipse fill=\"none\" stroke=\"black\" cx=\"-65.0031\" cy=\"28.0594\" rx=\"42.4939\" ry=\"18\"/>\r\n<text text-anchor=\"middle\" x=\"-65.0031\" y=\"31.7594\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Detector</text>\r\n</g>\r\n<!-- Uncalibrated -->\r\n<g id=\"node2\" class=\"node\"><title>Uncalibrated</title>\r\n<ellipse fill=\"none\" stroke=\"black\" cx=\"-47.6776\" cy=\"-53.0023\" rx=\"56.59\" ry=\"18\"/>\r\n<text text-anchor=\"middle\" x=\"-47.6776\" y=\"-49.3023\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Uncalibrated</text>\r\n</g>\r\n<!-- Detector&#45;&gt;Uncalibrated -->\r\n<g id=\"edge1\" class=\"edge\"><title>Detector&#45;&gt;Uncalibrated</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M-61.158,10.0692C-58.975,-0.144239 -56.1936,-13.1577 -53.725,-24.7081\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"-57.0847,-25.7345 -51.5718,-34.782 -50.2393,-24.2713 -57.0847,-25.7345\"/>\r\n</g>\r\n<!-- Read -->\r\n<g id=\"node4\" class=\"node\"><title>Read</title>\r\n<ellipse fill=\"none\" stroke=\"black\" cx=\"15.1486\" cy=\"2.70933\" rx=\"29.795\" ry=\"18\"/>\r\n<text text-anchor=\"middle\" x=\"15.1486\" y=\"6.40933\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Read</text>\r\n</g>\r\n<!-- Detector&#45;&gt;Read -->\r\n<g id=\"edge2\" class=\"edge\"><title>Detector&#45;&gt;Read</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M-31.0116,17.3087C-27.7689,16.2831 -24.4718,15.2403 -21.2079,14.208\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"-22.1934,10.8489 -11.6034,11.1704 -20.0825,17.5231 -22.1934,10.8489\"/>\r\n</g>\r\n<!-- Uncalibrated&#45;&gt;Read -->\r\n<g id=\"edge3\" class=\"edge\"><title>Uncalibrated&#45;&gt;Read</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M-28.4863,-35.9842C-22.4983,-30.6743 -15.8083,-24.7419 -9.50036,-19.1483\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"-6.95606,-21.57 -1.7962,-12.3166 -11.6004,-16.3326 -6.95606,-21.57\"/>\r\n</g>\r\n<!-- Object -->\r\n<g id=\"node3\" class=\"node\"><title>Object</title>\r\n<ellipse fill=\"none\" stroke=\"black\" cx=\"97.5321\" cy=\"22.2335\" rx=\"35.194\" ry=\"18\"/>\r\n<text text-anchor=\"middle\" x=\"97.5321\" y=\"25.9335\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Object</text>\r\n</g>\r\n<!-- Object&#45;&gt;Read -->\r\n<g id=\"edge4\" class=\"edge\"><title>Object&#45;&gt;Read</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M65.4446,14.629C61.2768,13.6413 56.978,12.6226 52.7309,11.616\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"51.9237,15.0217 43.0004,9.30997 53.538,8.21041 51.9237,15.0217\"/>\r\n</g>\r\n</g>\r\n</svg>\r\n",
      "text/plain": [
       "<graphviz.dot.Digraph at 0x1bf088e5eb0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer for 1 - Bayesian network structure\n",
    "\n",
    "G = Graph({\n",
    "    'Detector': ['Uncalibrated', 'Read'],\n",
    "    'Uncalibrated': ['Read'],\n",
    "    'Object': ['Read'],\n",
    "    'Read':[],\n",
    "})\n",
    "\n",
    "G.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer for 2**\n",
    "\n",
    "Detector, Uncalibrated and Object have can influence the read result together. So, they are directed to Read.\n",
    "\n",
    "Uncalibrated rate is only influenced by Detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'D': ('XP', 'Minelab'), 'U': ('yes', 'no'), 'O': ('treasure', 'trash'), 'R': ('treasure', 'trash')}\n",
      "╒═════════╤══════╕\n",
      "│ D       │   Pr │\n",
      "╞═════════╪══════╡\n",
      "│ XP      │  0.5 │\n",
      "├─────────┼──────┤\n",
      "│ Minelab │  0.5 │\n",
      "╘═════════╧══════╛\n",
      "\n",
      "╒═════════╤═════╤══════╕\n",
      "│ D       │ U   │   Pr │\n",
      "╞═════════╪═════╪══════╡\n",
      "│ XP      │ yes │ 0.01 │\n",
      "├─────────┼─────┼──────┤\n",
      "│ XP      │ no  │ 0.99 │\n",
      "├─────────┼─────┼──────┤\n",
      "│ Minelab │ yes │ 0.05 │\n",
      "├─────────┼─────┼──────┤\n",
      "│ Minelab │ no  │ 0.95 │\n",
      "╘═════════╧═════╧══════╛\n",
      "\n",
      "╒══════════╤══════╕\n",
      "│ O        │   Pr │\n",
      "╞══════════╪══════╡\n",
      "│ treasure │ 0.01 │\n",
      "├──────────┼──────┤\n",
      "│ trash    │ 0.99 │\n",
      "╘══════════╧══════╛\n",
      "\n",
      "╒═════════╤═════╤══════════╤══════════╤══════╕\n",
      "│ D       │ U   │ O        │ R        │   Pr │\n",
      "╞═════════╪═════╪══════════╪══════════╪══════╡\n",
      "│ XP      │ yes │ treasure │ treasure │  0.6 │\n",
      "├─────────┼─────┼──────────┼──────────┼──────┤\n",
      "│ XP      │ yes │ treasure │ trash    │  0.4 │\n",
      "├─────────┼─────┼──────────┼──────────┼──────┤\n",
      "│ XP      │ yes │ trash    │ treasure │  0.1 │\n",
      "├─────────┼─────┼──────────┼──────────┼──────┤\n",
      "│ XP      │ yes │ trash    │ trash    │  0.9 │\n",
      "├─────────┼─────┼──────────┼──────────┼──────┤\n",
      "│ XP      │ no  │ treasure │ treasure │  0.7 │\n",
      "├─────────┼─────┼──────────┼──────────┼──────┤\n",
      "│ XP      │ no  │ treasure │ trash    │  0.3 │\n",
      "├─────────┼─────┼──────────┼──────────┼──────┤\n",
      "│ XP      │ no  │ trash    │ treasure │  0.1 │\n",
      "├─────────┼─────┼──────────┼──────────┼──────┤\n",
      "│ XP      │ no  │ trash    │ trash    │  0.9 │\n",
      "├─────────┼─────┼──────────┼──────────┼──────┤\n",
      "│ Minelab │ yes │ treasure │ treasure │  0.6 │\n",
      "├─────────┼─────┼──────────┼──────────┼──────┤\n",
      "│ Minelab │ yes │ treasure │ trash    │  0.4 │\n",
      "├─────────┼─────┼──────────┼──────────┼──────┤\n",
      "│ Minelab │ yes │ trash    │ treasure │  0.2 │\n",
      "├─────────┼─────┼──────────┼──────────┼──────┤\n",
      "│ Minelab │ yes │ trash    │ trash    │  0.8 │\n",
      "├─────────┼─────┼──────────┼──────────┼──────┤\n",
      "│ Minelab │ no  │ treasure │ treasure │  0.7 │\n",
      "├─────────┼─────┼──────────┼──────────┼──────┤\n",
      "│ Minelab │ no  │ treasure │ trash    │  0.3 │\n",
      "├─────────┼─────┼──────────┼──────────┼──────┤\n",
      "│ Minelab │ no  │ trash    │ treasure │  0.2 │\n",
      "├─────────┼─────┼──────────┼──────────┼──────┤\n",
      "│ Minelab │ no  │ trash    │ trash    │  0.8 │\n",
      "╘═════════╧═════╧══════════╧══════════╧══════╛\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your answer for 3\n",
    "\n",
    "outcomeSpace = dict(\n",
    "    D=('XP','Minelab'),\n",
    "    U=('yes','no'),\n",
    "    O=('treasure','trash'),\n",
    "    R=('treasure','trash'),\n",
    ")\n",
    "\n",
    "BN = BayesNet(G, outcomeSpace)\n",
    "\n",
    "# Define the factors here and assign them to the Bayesian network BN\n",
    "\n",
    "# Factor for detector, set to 0.5 by default\n",
    "# Which is an uniform distribution\n",
    "d = Factor(('D',), outcomeSpace)\n",
    "d['XP'] = 0.5\n",
    "d['Minelab'] = 0.5\n",
    "BN.factors['D'] = d\n",
    "\n",
    "\n",
    "u = Factor(('D', 'U'), outcomeSpace)\n",
    "u['XP', 'no'] = 0.99\n",
    "u['XP', 'yes'] = 0.01\n",
    "u['Minelab', 'no'] = 0.95\n",
    "u['Minelab', 'yes'] = 0.05\n",
    "BN.factors['U'] = u\n",
    "\n",
    "o = Factor(('O',), outcomeSpace)\n",
    "o['treasure'] = 0.01\n",
    "o['trash'] = 0.99\n",
    "BN.factors['O'] = o\n",
    "\n",
    "r = Factor(('D', 'U', 'O', 'R'), outcomeSpace)\n",
    "r['XP', 'yes', 'treasure', 'treasure'] = 0.6\n",
    "r['XP', 'yes', 'treasure', 'trash'] = 0.4\n",
    "r['XP', 'yes', 'trash', 'treasure'] = 0.1\n",
    "r['XP', 'yes', 'trash', 'trash'] = 0.9\n",
    "r['XP', 'no', 'treasure', 'treasure'] = 0.7\n",
    "r['XP', 'no', 'treasure', 'trash'] = 0.3\n",
    "r['XP', 'no', 'trash', 'treasure'] = 0.1\n",
    "r['XP', 'no', 'trash', 'trash'] = 0.9\n",
    "\n",
    "r['Minelab', 'yes', 'treasure', 'treasure'] = 0.6\n",
    "r['Minelab', 'yes', 'treasure', 'trash'] = 0.4\n",
    "r['Minelab', 'yes', 'trash', 'treasure'] = 0.2\n",
    "r['Minelab', 'yes', 'trash', 'trash'] = 0.8\n",
    "r['Minelab', 'no', 'treasure', 'treasure'] = 0.7\n",
    "r['Minelab', 'no', 'treasure', 'trash'] = 0.3\n",
    "r['Minelab', 'no', 'trash', 'treasure'] = 0.2\n",
    "r['Minelab', 'no', 'trash', 'trash'] = 0.8\n",
    "BN.factors['R'] = r\n",
    "\n",
    "\n",
    "# Show outcome space and tables\n",
    "print(outcomeSpace)\n",
    "for f in BN.factors.values():\n",
    "    print(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒══════════╤═══════════╕\n",
      "│ O        │        Pr │\n",
      "╞══════════╪═══════════╡\n",
      "│ treasure │ 0.0448318 │\n",
      "├──────────┼───────────┤\n",
      "│ trash    │ 0.955168  │\n",
      "╘══════════╧═══════════╛\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your answer for 4\n",
    "\n",
    "answer = BN.query(['O'], R='treasure')\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Briefly comment on the results of 4 here**\n",
    "\n",
    "The result shows that given the read is treasure, the probability of the object to be treasure is **0.0448318**.\n",
    "\n",
    "The reason why it is lower than my expectation is that $P(O=treasure|R=treasure) = \\frac{P(O=treasure \\land R=treasure)}{P(R=treasure)}$ while $P(R=treasure)$ is much higher than numerator because 99% of objects are trash."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Question 6 [15 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture 10 discussed MAP queries. We developed the MPE VE and MAP VE algorithms based on the Variable Elimination (VE) algorithm. In lecture 11, we learned about jointrees. Suppose we want to replace the VE algorithm with the jointree algorithm for computing MAP and MPE queries. Answer the following questions:\n",
    "\n",
    "1. How can we redefine the jointree messages to answer maximum a posteriori queries?\n",
    "2. Will this new algorithm work for both MAP and MPE queries? **Briefly explain**.\n",
    "3. What are the benefits and limitations of this new approach compared with variable elimination?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer for 1**\n",
    "\n",
    "We can redefine the message for MAP variables as maximising out MAP variables in separator $S_{ij}$ instead of summing out them.\n",
    "\n",
    "With the redefined message, we need to carefully construct the tree to ensure that no maximising out  is topologically before summing out.\n",
    "\n",
    "An alternative is to summarize out non-MAP variables and to maximize out MAP variables at the same time, however, this cannot guarantee the correctness because the order is constrained. So we don't take the alternative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer for 2**\n",
    "\n",
    "Yes, after summing out all non-MAP variables, the maximum probability can be obtained by maximizing out the factor that contains all MAP variables.\n",
    "\n",
    "As answering a MPE query is a sub question of MAP, so it also works for MPE queries (obtained by maximising out every cluster)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer for 3**\n",
    "\n",
    "**Benefits:**\n",
    "+ Some messages can be reused to reduce the time complexity\n",
    "+ Can avoid frequently destroying and reconstructing factors of the graph. \n",
    "+ Especially efficient for MPE queries as there is no constraint on tree structure.\n",
    "\n",
    "**Limitations:**\n",
    "+ MAP queries have constrained order, which means that the some jointrees structures are not applicable, this limits the usability of constructed jointrees.\n",
    "+ Constructing an appropriate tree can be sometimes complex especially when there are more nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Question 7 [15 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Lecture 15, we performed inference by creating and counting samples. We generated those samples by simulating a Bayesian Network $N$, and we learned that this simulation could be difficult in the presence of evidence. Now, suppose we have a jointree with cluster marginals $P(C_i|\\textbf{e})$ and separator marginals $P(S_{ij}|\\textbf{e})$ obtained with the execution of the jointree algorithm on the network $N$ and evidence $\\textbf{e}$.\n",
    "\n",
    "1. Provide an efﬁcient algorithm for simulating $N$ conditioned on $\\textbf{e}$ given the cluster and separator marginals. \n",
    "2. Argue that your algorithm generates a sequence of independent network instantiations $x_1, ... , x_n$ where the probability of generating an instance $x_i$ is $P(x_i|\\textbf{e})$.\n",
    "3. Discuss the complexity of your algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer for 1**\n",
    "\n",
    "Recurrently pick a cluster that only has one neighbour. Then, eliminate and sample the variables that only appear in that cluster. After that, remove the cluster and repeat until every cluster is removed.\n",
    "\n",
    "The variables are sampled according to $P(x_i|e)$ which is obtained by summing out all other variables in the cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer for 2**\n",
    "\n",
    "This algorithm can guarantee that every variable is sampled once because of the feature of jointree.\n",
    "\n",
    "Also, when eliminating a certain variable, it is guaranteed that the current cluster has combined all the factors containing that variable. This is because the variable doesn't appear in the rest part of the jointree. Therefore, it can guarantee that the probability used is $P(x_i|e)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer for 3**\n",
    "\n",
    "Sampling a single variable has complexity $O(w)$ where w is miximum number of variables in a cluster.\n",
    "\n",
    "This complexity is not higher than that of eliminating a variable which is $O(exp(w))$\n",
    "\n",
    "Therefore, the final conplexity is just the complexity of variable elimination on jointree which is $O(n\\ exp(w))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# Part 3 [30 marks]\n",
    "\n",
    "Part 3 is composed of two programming questions of 15 marks each. Use the code cell after each question statement to enter your answer. You can use the code of the tutorials in your answers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Question 8 [15 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Lecture 11, we learned about jointrees. These probabilistic graphical models must obey a property known as *running intersection* to be considered proper jointrees. Implement a function ``RIP(J)`` that returns **true** if the jointree ``J`` obeys the running intersection property and **false** otherwise. The argument `J` is a jointree object as defined in the tutorials and below.\n",
    "\n",
    "You may assume that each cluster in the graph is named with a string of length 1. The separator labels are sorted in numeric or alphabetical order. Note that this question will be autotested, so do not change any code outside of the area specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write our answer for Question 8 here\n",
    "\n",
    "def dfs(J, i, v, visited, seen):\n",
    "    # If visited this state before and the program\n",
    "    # didn't exit, it means that the tree is good so far.\n",
    "    if visited[i][v]:\n",
    "        return True\n",
    "    # If seen the variable before but didn't visit it\n",
    "    # it means that it is not connected to the previous ones.\n",
    "    if seen[v]:\n",
    "        return False\n",
    "    # Visit this state\n",
    "    visited[i][v] = True\n",
    "    # dfs search\n",
    "    for j in J.graph.adj_list[i]:\n",
    "        # If j doesn't contain v, they are not connected.\n",
    "        if v not in J.clusters[j]:\n",
    "            continue\n",
    "        # skip visited\n",
    "        if visited[j][v]:\n",
    "            continue\n",
    "        # Check separator\n",
    "        ij = i+j\n",
    "        if v not in J.separators[ij]:\n",
    "            return False\n",
    "        # dfs connected clusters\n",
    "        result = dfs(J, j, v, visited, seen)\n",
    "        \n",
    "        # pass False \n",
    "        if result == False:\n",
    "            return False\n",
    "    \n",
    "    # Null hypothesis: True\n",
    "    return True\n",
    "\n",
    "def RIP(J):\n",
    "    # var contains all variables\n",
    "    var = []\n",
    "    for f in J.clusters.values():\n",
    "        for v in f:\n",
    "            if v not in var:\n",
    "                var.append(v)\n",
    "    \n",
    "    # visited and seen keep visit info\n",
    "    visited = {i:{v:False for v in var} for i in J.clusters}\n",
    "    seen = {v:False for v in var}\n",
    "    \n",
    "    # loop through every cluster\n",
    "    for i, f in zip(J.clusters, J.clusters.values()):\n",
    "        for v in f:\n",
    "            result = dfs(J, i, v, visited, seen)\n",
    "            # Reject \n",
    "            if result == False:\n",
    "                return False\n",
    "    \n",
    "    # Null hypothesis: True\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "# Test code\n",
    "\n",
    "class JoinTree():\n",
    "    def __init__(self, graph, clusters, separators):\n",
    "        self.graph = graph\n",
    "        self.separators = separators\n",
    "        self.clusters = clusters\n",
    "\n",
    "G = Graph({\n",
    "    '1': ('2',),\n",
    "    '2': ('1', '3', '4'),\n",
    "    '3': ('2',),\n",
    "    '4': ('2', '5'),\n",
    "    '5': ('4',),\n",
    "})\n",
    "\n",
    "S = {\n",
    "    '12': ('S', 'V'),\n",
    "    '23': ('V',),\n",
    "    '24': ('O',),\n",
    "    '45': ('T',),\n",
    "}\n",
    "\n",
    "C = {\n",
    "    '1': ('S', 'L', 'H', 'V'),\n",
    "    '2': ('O', 'S', 'V'),\n",
    "    '3': ('C', 'V'),\n",
    "    '4': ('B', 'O', 'T'),\n",
    "    '5': ('A', 'T'),\n",
    "}\n",
    "\n",
    "jt = JoinTree(G, C, S)\n",
    "\n",
    "print(RIP(jt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "### Question 9 [15 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture 15 presented approaches for inference using sampling. We saw how we could implement the Likelihood Weighting algorithm for discrete networks. In this question, we ask you to implement Likelihood Weighting for Gaussian Bayesian networks.\n",
    "\n",
    "Fill in the `likelihood_weighted_sampling` method on the GaussianBayesNet class. The section to be filled is shown with `... #TODO`. Note that each factor in the Bayes Net will be a Gaussian Factor object.\n",
    "\n",
    "The GaussianFactor class is provided in the file `GaussianFactor.py` for your convenience.\n",
    "\n",
    "Note that this question will be autotested, so do not change any code outside of the area specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer for Question 8 here\n",
    "\n",
    "class GaussianBayesNet():\n",
    "    def __init__(self, graph, factor_dict=None):\n",
    "        self.graph = graph\n",
    "        self.factors = dict()\n",
    "        if factor_dict is not None:\n",
    "            self.factors = factor_dict\n",
    "    \n",
    "    def likelihood_weighted_sampling(self, n_samples, **evidence):\n",
    "        '''\n",
    "        This function returns a list of samples drawn randomly from the BayesNet distribution.\n",
    "        Arguments:\n",
    "            `n_samples`: number of samples to generate\n",
    "            `evidence`: a dictionary of observations\n",
    "        \n",
    "        returns: \n",
    "            weights: List of weights. E.g. [6.823e-05, 1.1409e-50,]\n",
    "            samples: List of sample dicts. E.g. [{'A':0.3, 'B':-1.7, 'C':1.1},{'A':-0.2, 'B':2.01, 'C':2.1},]\n",
    "        '''\n",
    "        weights = []\n",
    "        samples = []\n",
    "        \n",
    "        ########### Answer below\n",
    "        for iters in range(n_samples):\n",
    "            sigma = {}\n",
    "            order = self.graph.topological_sort()\n",
    "            w = 1\n",
    "            for i in range(len(order)):\n",
    "                X = order[i]\n",
    "                u = {}\n",
    "                for s,j in zip(samples, order):\n",
    "                    if i in self.graph.adj_list[j]:\n",
    "                        u[j] = s\n",
    "                if X in evidence:\n",
    "                    sigma[X] = evidence[X]\n",
    "                    entry = tuple(sigma[v] for v in self.factors[X].domain)\n",
    "                    w = w * self.factors[X].density(entry)\n",
    "                else:\n",
    "                    sigma.update(self.factors[X].sample(**sigma))\n",
    "                \n",
    "            samples.append(sigma)\n",
    "            weights.append(w)\n",
    "        \n",
    "        ###########\n",
    "        \n",
    "        return weights, samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'A': 1.6582660213519174, 'B': 2.7, 'C': -7.033160423264499}, {'A': 0.16567425846707917, 'B': 2.7, 'C': -7.037009509064924}, {'A': 1.7035760664826216, 'B': 2.7, 'C': -7.0253783213588115}, {'A': 0.8385662070563838, 'B': 2.7, 'C': -6.882081412302271}, {'A': 0.9483193243707502, 'B': 2.7, 'C': -7.015216624363719}]\n",
      "[1.6145464481364207e-28, 8.99293023145651e-27, 5.629900168165687e-32, 1.304620118212548, 1.5339394107648283]\n"
     ]
    }
   ],
   "source": [
    "############\n",
    "# Test code\n",
    "\n",
    "graph = Graph({'A':['B'], 'B':['C'], 'C':[]})\n",
    "\n",
    "gbn = GaussianBayesNet(graph)\n",
    "gbn.factors['A'] = GaussianFactor(['A'], mu=1, sigma=1**2)\n",
    "gbn.factors['B'] = GaussianFactor(['B','A'], beta=[3], b_mean=0, b_var=0.2**2)\n",
    "gbn.factors['C'] = GaussianFactor(['C','B'], beta=[-3], b_mean=1, b_var=0.2**2)\n",
    "\n",
    "weights, samples = gbn.likelihood_weighted_sampling(5,B=2.7)\n",
    "\n",
    "print(samples)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example output:\n",
    "```\n",
    "[{'A': 0.348216516404394, 'B': 2.7, 'C': -7.188024942397417}, {'A': 0.01839518456395206, 'B': 2.7, 'C': -7.103155084034539}, {'A': 1.1960021809931205, 'B': 2.7, 'C': -6.979657064371987}, {'A': 0.39587510763503886, 'B': 2.7, 'C': -6.978733681701745}, {'A': 0.9996062580578883, 'B': 2.7, 'C': -7.014497964752619}]\n",
    "[2.656373475856643e-15, 2.118460658582052e-38, 0.00010448721114381634, 7.638040102473492e-13, 0.6533391788451658]\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "198px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "783px",
    "left": "0px",
    "right": "1346.87px",
    "top": "108px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
